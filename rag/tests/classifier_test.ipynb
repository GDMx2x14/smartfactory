{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier LLM test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Predict the trend of working_time_avg for Lase...</td>\n",
       "      <td>predictions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Predict the future working_time_max for Assemb...</td>\n",
       "      <td>predictions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Predict the future offline_time_min for Assemb...</td>\n",
       "      <td>predictions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Predict the future offline_time_sum for Riveti...</td>\n",
       "      <td>predictions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Can you predict idle_time_avg for Laser Weldin...</td>\n",
       "      <td>predictions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Find a dashboard suitable to give an overview ...</td>\n",
       "      <td>dashboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Generate a new random dashboard</td>\n",
       "      <td>dashboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>I need to monitor the productivity of the work...</td>\n",
       "      <td>dashboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>I need to monitor the energy consumption of my...</td>\n",
       "      <td>dashboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Generate a console to control the costs</td>\n",
       "      <td>dashboard</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text        label\n",
       "1   Predict the trend of working_time_avg for Lase...  predictions\n",
       "2   Predict the future working_time_max for Assemb...  predictions\n",
       "3   Predict the future offline_time_min for Assemb...  predictions\n",
       "4   Predict the future offline_time_sum for Riveti...  predictions\n",
       "5   Can you predict idle_time_avg for Laser Weldin...  predictions\n",
       "..                                                ...          ...\n",
       "68  Find a dashboard suitable to give an overview ...    dashboard\n",
       "69                    Generate a new random dashboard    dashboard\n",
       "70  I need to monitor the productivity of the work...    dashboard\n",
       "71  I need to monitor the energy consumption of my...    dashboard\n",
       "72            Generate a console to control the costs    dashboard\n",
       "\n",
       "[72 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = open(\"classifier_val_dataset.txt\",\"r\")\n",
    "text = []\n",
    "label = []\n",
    "for line in dataset.readlines():\n",
    "    if line == \"\\n\":\n",
    "        continue\n",
    "    line = line.split(\":\")\n",
    "    line = [x.strip(\" \\n\") for x in line]\n",
    "    text.append(line[0])\n",
    "    label.append(line[1])\n",
    "dataset = pd.DataFrame({\"text\": text, \"label\": label},index=[i+1 for i in range(len(text))])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook starts with the communication initializzation to _Gemini_1.5_flash_ API.<br>\n",
    "The prompt classification is made using gemini with few shot learning, using an example for each classification label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gdema\\Anaconda3\\envs\\SA\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import sys\n",
    "\n",
    "current_dir = %pwd\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, '../'))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "load_dotenv(dotenv_path=parent_dir + \"\\RAG\\.env\")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "\n",
    "# few shots examples\n",
    "esempi = [\n",
    "    {\"text\": \"Predict for the next month the cost_working_avg for Large Capacity Cutting Machine 2 based on last three months data\", \"label\": \"predictions\"},\n",
    "    {\"text\": \"Generate a new kpi named machine_total_consumption which use some consumption kpis to be calculated\", \"label\": \"new_kpi\"},\n",
    "    {\"text\": \"Compute the Maintenance Cost for the Riveting Machine 1 for yesterday\", \"label\": \"kpi_calc\"},\n",
    "    {\"text\": \"Can describe cost_working_avg?\", \"label\": \"kb_q\"},\n",
    "    {\"text\": \"Make a report about bad_cycles_min for Laser Welding Machine 1 with respect to last week\", \"label\": \"report\"},\n",
    "    {\"text\": \"Create a dashboard to compare perfomances for different type of machines\", \"label\": \"dashboard\"},\n",
    "]\n",
    "\n",
    "# Few shot prompt creation\n",
    "esempio_template = PromptTemplate(\n",
    "    input_variables=[\"text\", \"label\"],\n",
    "    template=\"Text: {text}\\nLabel: {label}\\n\"\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=esempi,\n",
    "    example_prompt=esempio_template,\n",
    "    suffix=\"Classify with one of the labels ['predictions', 'new_kpi', 'report', 'kb_q', 'dashboard','kpi_calc'] the following prompt:\\nText: {text_input}\\nLabel:\",\n",
    "    input_variables=[\"text_input\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start testing few shot learning on the dataset to fine-tune prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [04:49<00:00,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 1.0\n",
      "There have been 0 wrong predictions:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "true_pos=0\n",
    "mismatch = []\n",
    "total = dataset.shape[0]\n",
    "\n",
    "with tqdm(total=total) as bar:\n",
    "    for (text,golden_label) in zip(dataset[\"text\"],dataset[\"label\"]):\n",
    "        local_time = time.time()\n",
    "        prompt = few_shot_prompt.format(text_input=text)\n",
    "        out = llm.invoke(prompt)\n",
    "        out=out.content.strip(\"\\n\")\n",
    "        if out == golden_label:\n",
    "            true_pos+=1\n",
    "        else:\n",
    "            mismatch.append(f\"text = {text}\\nTrue label = {golden_label}, predicted = {out}\")\n",
    "        bar.update(1)\n",
    "        # Request rate must be limited to 4 requests per second (free API limit)\n",
    "        time.sleep(4 - (time.time() - local_time) + 0.01)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "print(f\"Accuracy = {true_pos/total}\")\n",
    "print(f\"There have been {len(mismatch)} wrong predictions:\")\n",
    "for i in mismatch:\n",
    "    print(mismatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SA_",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
